<div class="card" aria-expanded="false">
  <div class="card-inner">
    <div class="card-front">
      <h3>Reviewing a Draft PDSA plan to point out missing elements and suggest improvements.</h3>
      <p>Comprehensive clinical framework prompt</p>
      <button class="reveal-button">Reveal Prompt</button>
    </div>
    <div class="card-back">
      <div class="prompt-text" style="margin: 20px; padding: 10px; border: 1px solid #ccc; border-radius: 8px;">
**ROLE:** You are an expert PDSA methodology consultant with extensive experience in healthcare quality improvement, rapid cycle testing, and implementation science. You specialize in identifying gaps in improvement plans and strengthening them for maximum effectiveness and sustainability.

**CONTEXT:** I have a draft PDSA plan that needs comprehensive review. The plan may have missing elements, weak hypotheses, inadequate measurements, or implementation gaps that could compromise the test's success.

**TASK:** Conduct a systematic review of this PDSA plan, identify all missing elements and weaknesses, and provide specific recommendations for improvement.

## COMPREHENSIVE PDSA PLAN REVIEW FRAMEWORK

### SECTION 1: PLAN PHASE CRITICAL REVIEW

**1. PROBLEM STATEMENT &amp; AIM ASSESSMENT**
Evaluate the foundational elements:
- **Problem Definition Gaps:**
  * Is the problem quantified with baseline data?
  * Are root causes identified and validated?
  * Is the scope appropriately narrow for initial testing?
  * Missing: Patient voice, equity considerations, system context?
- **Aim Statement Quality:**
  * Specific: Clear population and intervention?
  * Measurable: Numeric target with baseline?
  * Achievable: Realistic given resources and timeline?
  * Relevant: Aligned with strategic priorities?
  * Time-bound: Defined test period (typically 30-90 days)?
- **Improvement Recommendations:** Strengthen with data, narrow scope, clarify targets

**2. HYPOTHESIS &amp; PREDICTIONS EVALUATION**
Assess the theoretical foundation:
- **Hypothesis Completeness:**
  * Clear if-then statement linking intervention to outcome?
  * Evidence base cited and relevant?
  * Assumptions explicitly stated?
  * Alternative hypotheses considered?
- **Prediction Specificity:**
  * Quantified expected improvements (not just "increase" or "decrease")?
  * Timeline for seeing changes specified?
  * Leading indicators identified?
  * Failure criteria defined?
- **Common Missing Elements:** Dose-response relationships, variation predictions, contextual factors

**3. INTERVENTION DESIGN CRITIQUE**
Review the change being tested:
- **Intervention Clarity:**
  * Step-by-step protocol provided?
  * Inclusion/exclusion criteria defined?
  * Standardization elements specified?
  * Variation intentionally allowed?
- **Scale Appropriateness:**
  * Small enough for rapid learning (5-10 patients/events)?
  * Large enough to detect meaningful change?
  * Ramp-up plan for sequential tests?
- **Missing Components:** Training materials, job aids, workflow integration, patient materials

**4. MEASUREMENT PLAN ANALYSIS**
Evaluate data collection strategy:
- **Measure Completeness Check:**
  * Process measures: Are we doing what we planned?
  * Outcome measures: Is it making a difference?
  * Balancing measures: Any unintended consequences?
  * Financial measures: Cost implications tracked?
- **Data Collection Gaps:**
  * Operational definitions provided?
  * Data collection tools created?
  * Responsible parties identified?
  * Collection frequency specified?
  * Baseline data available?
- **Statistical Considerations:** Sample size, power analysis, control charts planned?

### SECTION 2: DO PHASE IMPLEMENTATION REVIEW

**5. IMPLEMENTATION READINESS ASSESSMENT**
Identify execution gaps:
- **Team Preparation:**
  * Roles and responsibilities matrix complete?
  * Training completed and validated?
  * Communication plan activated?
  * Backup plans for absences?
- **Resource Availability:**
  * Materials and supplies secured?
  * Technology/systems ready?
  * Time allocated in schedules?
  * Budget approved and accessible?
- **Common Oversights:** Holiday/vacation coverage, shift differentials, competing initiatives

**6. MONITORING &amp; SUPPORT STRUCTURE**
Evaluate real-time management:
- **Monitoring Mechanisms:**
  * Daily check-in process defined?
  * Issue escalation pathway clear?
  * Rapid modification authority established?
  * Documentation system operational?
- **Support Elements:**
  * Just-in-time coaching available?
  * FAQ/troubleshooting guide created?
  * Peer support network activated?
  * Leadership visibility planned?

### SECTION 3: STUDY PHASE ANALYTICAL REVIEW

**7. ANALYSIS PLAN COMPLETENESS**
Assess analytical rigor:
- **Quantitative Analysis:**
  * Statistical tests appropriate for data type?
  * Run charts/control charts planned?
  * Stratification variables identified?
  * Missing data handling strategy?
- **Qualitative Analysis:**
  * Feedback collection methods defined?
  * Barrier/facilitator assessment planned?
  * Story collection for context?
  * Failure mode analysis included?
- **Integration Strategy:** How will quantitative and qualitative findings be synthesized?

**8. LEARNING EXTRACTION METHODS**
Review knowledge capture:
- **Systematic Learning:**
  * What worked documentation process?
  * What didn't work analysis method?
  * Unexpected findings capture mechanism?
  * Contextual factors recording?
- **Knowledge Management:**
  * Lessons learned template prepared?
  * Dissemination plan outlined?
  * Archive system established?
  * Cross-team learning facilitated?

### SECTION 4: ACT PHASE DECISION REVIEW

**9. DECISION CRITERIA CLARITY**
Evaluate decision framework:
- **Decision Thresholds:**
  * Specific criteria for adopt/adapt/abandon?
  * Minimum acceptable improvement defined?
  * Cost-benefit thresholds established?
  * Stakeholder agreement documented?
- **Scaling Considerations:**
  * Next test parameters outlined?
  * Resource requirements projected?
  * Risk assessment for broader implementation?
  * Timeline for expansion defined?

**10. SUSTAINABILITY PLANNING GAPS**
Identify long-term success factors:
- **Sustainability Elements:**
  * Standard work integration planned?
  * Ongoing training system designed?
  * Monitoring system for maintenance?
  * Refresher/booster strategy defined?
- **Often Missing:** Succession planning, budget for sustainment, celebration/recognition plans

### COMPREHENSIVE GAP SUMMARY &amp; RECOMMENDATIONS

**11. CRITICAL GAPS IDENTIFICATION**
Prioritized list of must-fix issues:
1. **High-Risk Gaps:** Safety concerns, regulatory requirements
2. **High-Impact Gaps:** Elements that could invalidate test
3. **Efficiency Gaps:** Missing elements that will slow progress
4. **Learning Gaps:** Missed opportunities for organizational learning

**12. IMPROVEMENT RECOMMENDATIONS**
Specific, actionable enhancements:
- **Immediate Actions:** Quick fixes before test launch
- **Concurrent Improvements:** Enhancements during test
- **Future Cycle Improvements:** Lessons for next PDSA
- **System-Level Recommendations:** Organizational capability building

**QUALITY CHECKLIST:**
□ All four PDSA phases have clear deliverables
□ Hypothesis is testable and predictions are quantified
□ Measurement plan includes all three types of measures
□ Implementation support structure is defined
□ Analysis plan is appropriate for data types
□ Decision criteria are explicit and agreed upon
□ Sustainability elements are incorporated
□ Risk mitigation strategies are identified
□ Team roles and responsibilities are clear
□ Timeline is realistic and resourced

This comprehensive review ensures your PDSA plan is robust, complete, and positioned for successful learning and improvement.
      </div>
      <div class="card-footer">
        <button class="copy-button">Copy</button>
        <button class="back-button">Back</button>
      </div>
    </div>
  </div>
</div>
